{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51451fa-373a-4862-a32a-788a0286f516",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b91a95-88b4-4d84-8647-a1b3c0e8f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd10d18-a24a-40ce-b5e2-0668b5bc9bc2",
   "metadata": {},
   "source": [
    "# CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f3b93d4-a94b-4e6b-a77a-a5076d281d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10CnnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            # Conv-1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            # Conv-2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            \n",
    "            # Conv-3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            # Conv-4\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2), # output: 128 x 8 x 8\n",
    "\n",
    "            # Conv-5\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),            \n",
    "            \n",
    "            # Conv-6\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),           \n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2), # output: 256 x 4 x 4\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 32),\n",
    "            nn.Dropout(0.25),            \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766548f4-6224-4549-b462-ca660039b488",
   "metadata": {},
   "source": [
    "# Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "953d5d72-939d-45e8-8a13-2ff49de8ddb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cifar10CnnModel(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.25, inplace=False)\n",
       "    (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU()\n",
       "    (15): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (18): ReLU()\n",
       "    (19): Dropout(p=0.25, inplace=False)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU()\n",
       "    (23): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (24): Flatten(start_dim=1, end_dim=-1)\n",
       "    (25): Linear(in_features=4096, out_features=32, bias=True)\n",
       "    (26): Dropout(p=0.25, inplace=False)\n",
       "    (27): ReLU()\n",
       "    (28): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = Cifar10CnnModel()\n",
    "saved_model.load_state_dict(torch.load('../saved_model/cifar10-cnn_with_bn_and_avg_pool.pth', map_location=torch.device('cpu')))\n",
    "saved_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff8fe92-bb8a-40ce-94ce-52f671409692",
   "metadata": {},
   "source": [
    "# Performing prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61636c-28ff-4ea3-a746-5a05d898ac6e",
   "metadata": {},
   "source": [
    "### Loading image for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df341863-3c6e-43f7-8388-9f2458b4e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.load(\"./test_images/image_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08faffa-cb0c-4920-b0b8-a1d46e0a7f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7922, 0.7922, 0.8000,  ..., 0.8118, 0.8039, 0.7961],\n",
       "         [0.8078, 0.8078, 0.8118,  ..., 0.8235, 0.8157, 0.8078],\n",
       "         [0.8235, 0.8275, 0.8314,  ..., 0.8392, 0.8314, 0.8235],\n",
       "         ...,\n",
       "         [0.8549, 0.8235, 0.7608,  ..., 0.9529, 0.9569, 0.9529],\n",
       "         [0.8588, 0.8510, 0.8471,  ..., 0.9451, 0.9451, 0.9451],\n",
       "         [0.8510, 0.8471, 0.8510,  ..., 0.9373, 0.9373, 0.9412]],\n",
       "\n",
       "        [[0.8000, 0.8000, 0.8078,  ..., 0.8157, 0.8078, 0.8000],\n",
       "         [0.8157, 0.8157, 0.8196,  ..., 0.8275, 0.8196, 0.8118],\n",
       "         [0.8314, 0.8353, 0.8392,  ..., 0.8392, 0.8353, 0.8275],\n",
       "         ...,\n",
       "         [0.8510, 0.8196, 0.7608,  ..., 0.9490, 0.9490, 0.9529],\n",
       "         [0.8549, 0.8471, 0.8471,  ..., 0.9412, 0.9412, 0.9412],\n",
       "         [0.8471, 0.8431, 0.8471,  ..., 0.9333, 0.9333, 0.9333]],\n",
       "\n",
       "        [[0.7804, 0.7804, 0.7882,  ..., 0.7843, 0.7804, 0.7765],\n",
       "         [0.7961, 0.7961, 0.8000,  ..., 0.8039, 0.7961, 0.7882],\n",
       "         [0.8118, 0.8157, 0.8235,  ..., 0.8235, 0.8157, 0.8078],\n",
       "         ...,\n",
       "         [0.8706, 0.8392, 0.7765,  ..., 0.9686, 0.9686, 0.9686],\n",
       "         [0.8745, 0.8667, 0.8627,  ..., 0.9608, 0.9608, 0.9608],\n",
       "         [0.8667, 0.8627, 0.8667,  ..., 0.9529, 0.9529, 0.9529]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42227fef-0a65-4ee5-9cc0-1a4d28475adf",
   "metadata": {},
   "source": [
    "### Function to diaplay image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9ac139-2a03-4f6b-8db8-cf103615454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n",
    "\n",
    "def display_image(img):\n",
    "    # print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89bd5a5-ce17-4c71-9c0f-3b27fa27f21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa1add-8939-4672-b334-b702943dd757",
   "metadata": {},
   "source": [
    "### Making the image fit for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b1d8479-98cf-4050-8146-56a6413a60c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_input_image = input_image[None,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e738518-5b08-44c3-963e-3cb1891ca646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_input_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf1168-9b01-4ad7-9ee5-2c4035707bad",
   "metadata": {},
   "source": [
    "### Performing prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc83194d-5803-4b7a-931a-af6331d1ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = saved_model(resized_input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281adf59-6d81-47c3-bab7-37e6a958ee6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.9999, -13.6704,  -7.8744, -19.9206, -11.0847, -40.7090, -30.9490,\n",
       "         -27.8359,  -7.4508,  -9.0774]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34f753c9-8891-4087-b711-3a50cfda291d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.9999, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e46e43d-70b4-4546-afd7-2cac149f3e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = output.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d42c65e-d108-4ab9-b662-efa8e9bd31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index = output_list[0].index(max(output_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad02cd-a8c4-4935-8bfe-58ffb42ac903",
   "metadata": {},
   "source": [
    "### Classes of CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f17e6d9-8fd5-442a-8a7d-bba26d6b8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "823d898d-dcab-4af8-bf06-ed72878b3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input is an image of airplane\n"
     ]
    }
   ],
   "source": [
    "print(\"The input is an image of\", classes[prediction_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641fbff5-634b-4425-b869-7e6983a2a295",
   "metadata": {},
   "source": [
    "# Getting the parameters (input and output) of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3de71e-0da6-48db-87fd-6de5353dab92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.9999, -13.6704,  -7.8744, -19.9206, -11.0847, -40.7090, -30.9490,\n",
       "         -27.8359,  -7.4508,  -9.0774]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a dictionary to store the outputs of each layer\n",
    "outputs = {}\n",
    "\n",
    "conv = []\n",
    "\n",
    "batch_norm = []\n",
    "\n",
    "relu = []\n",
    "\n",
    "pool = []\n",
    "\n",
    "flatten = []\n",
    "\n",
    "linear = []\n",
    "\n",
    "# Register a hook for each layer in the model\n",
    "def hook(module, input, output):\n",
    "    module_str = str(module)\n",
    "    outputs[module_str] = output\n",
    "        \n",
    "    if module_str[0] == 'C':\n",
    "        conv.append(\"################## LAYER ##################\")\n",
    "        conv.append(output)\n",
    "    elif module_str[0] == 'B':\n",
    "        batch_norm.append(\"################## LAYER ##################\")\n",
    "        batch_norm.append(output)\n",
    "    elif module_str[0] == 'A':\n",
    "        pool.append(\"################## LAYER ##################\")\n",
    "        pool.append(output)\n",
    "    elif module_str[0] == 'R':\n",
    "        relu.append(\"################## LAYER ##################\")\n",
    "        relu.append(output)\n",
    "    elif module_str[0] == 'F':\n",
    "        flatten.append(\"################## LAYER ##################\")\n",
    "        flatten.append(output)\n",
    "    elif module_str[0] == 'L':\n",
    "        linear.append(\"################## LAYER ##################\")\n",
    "        linear.append(output)\n",
    "\n",
    "        \n",
    "    \n",
    "for name, module in saved_model.named_modules():\n",
    "    module.register_forward_hook(hook)\n",
    "\n",
    "# Perform inference on an input image\n",
    "saved_model(resized_input_image)\n",
    "\n",
    "# Print the output of each layer\n",
    "# for name, output in outputs.items():\n",
    "#     print(name, output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6819ef-7460-4da4-b4d9-003c9ff206ed",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a581dd3a-38f0-4109-b493-8f864421d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_if_not_exists(base_path, name_of_folder=None):\n",
    "    path = base_path + \"/\" + name_of_folder + \"/\"\n",
    "    try:\n",
    "        if name_of_folder != None:\n",
    "            os.makedirs(base_path + \"/{}\".format(name_of_folder))\n",
    "        else:\n",
    "            os.makedirs(base_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    return path\n",
    "\n",
    "def write_tensor_to_file(tensor, file_path, name_of_file):\n",
    "    text_file = open(file_path + \"/{}\".format(name_of_file), \"w+\")\n",
    "    tensor.data.numpy().tofile(text_file, sep=\" \", format=\"%.8f\")\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257a4310-e416-4c3c-8bd4-79f588d01b47",
   "metadata": {},
   "source": [
    "# Saving output to text file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd09582-e1af-4411-9b88-5c93fd694e02",
   "metadata": {},
   "source": [
    "### Location where the parameters need to be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60bddd18-68ef-49e2-8b46-66cc5e354bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_where_all_parameters_be_stored = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c019624-8071-43f9-9c8d-85e55c617fb7",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1330e-4590-40f7-8c77-18d9d9f2a698",
   "metadata": {},
   "source": [
    "### Creating a directory to store convolution layer's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2ee9267-d159-41ff-89e5-ae3bd66b0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_path = create_if_not_exists(path_where_all_parameters_be_stored, \"conv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa1af6c1-9a21-4b63-aacc-83906c6332da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./conv/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb4d68-78fc-4936-902f-161c7b5be6b3",
   "metadata": {},
   "source": [
    "### Saving convolution layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "406892b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting last layer of conv as it is saved in linear layer\n",
    "for i in range(0,2):\n",
    "    conv.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "528725ab-b29d-485a-9922-a69c9b79aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "for i in range(0,len(conv)):\n",
    "    if type(conv[i]) != str:\n",
    "        conv_tensor = conv[i]\n",
    "        write_tensor_to_file(conv_tensor, conv_path, \"conv_layer_{}.txt\".format(layer))\n",
    "        layer += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0561c23f-e364-446d-955b-81945e847db9",
   "metadata": {},
   "source": [
    "## Average pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363874b-2447-424e-9568-3c6134166958",
   "metadata": {},
   "source": [
    "### Creating a directory to store average pooling layer's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "919bdae2-be5f-48f3-b015-02cdc092f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pool_path = create_if_not_exists(path_where_all_parameters_be_stored, \"avg_pool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9d430ef-c441-4c1b-a5ea-7b4bc0e76f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./avg_pool/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd763a9-98d1-4809-976b-bbd1cfb8dac7",
   "metadata": {},
   "source": [
    "### Saving average pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a72eb7b-71a0-4f2e-8d3f-79fcc6bb45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "for i in range(0,len(pool)):\n",
    "    if type(pool[i]) != str:\n",
    "        pool_tensor = pool[i]\n",
    "        write_tensor_to_file(pool_tensor, avg_pool_path, \"avg_pool_layer_{}.txt\".format(layer))\n",
    "        layer += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7003b0-be1d-4578-84c5-122a429f2e30",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4678b-8a11-4e96-a816-e98d7f22ee77",
   "metadata": {},
   "source": [
    "### Creating a directory to store batch normalization layer's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d482871-0d12-44ec-bd4a-078a4f080624",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm_path = create_if_not_exists(path_where_all_parameters_be_stored, \"batch_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92b403a9-6b2b-4bd0-adbd-72c127815fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./batch_norm/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba0e63-dbe0-482d-81f4-eba42108a6fd",
   "metadata": {},
   "source": [
    "### Saving batch_normalization layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9ce659f-afaf-45ce-8919-169889a2eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "for i in range(0,len(batch_norm)):\n",
    "    if type(batch_norm[i]) != str:\n",
    "        batch_norm_tensor = batch_norm[i]\n",
    "        write_tensor_to_file(batch_norm_tensor, batch_norm_path, \"batch_norm_layer_{}.txt\".format(layer))\n",
    "        layer += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8ec33-6a86-4dff-b6fe-6a3a00a8de64",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec556b-f62a-4c5e-8b01-67ede32fb75f",
   "metadata": {},
   "source": [
    "### Creating a directory to store flatten layer's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31448ec5-6348-4c06-9965-364286a7ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_path = create_if_not_exists(path_where_all_parameters_be_stored, \"flatten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "346bc849-7d55-4ef4-9a7a-17b1f62059ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./flatten/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234897b-0348-4a90-aa01-4c5bdede6431",
   "metadata": {},
   "source": [
    "### Saving flatten layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe0bc412-513b-47d2-9c39-988260ff1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "for i in range(0,len(flatten)):\n",
    "    if type(flatten[i]) != str:\n",
    "        flatten_tensor = flatten[i]\n",
    "        write_tensor_to_file(flatten_tensor, flatten_path, \"flatten_layer_{}.txt\".format(layer))\n",
    "        layer += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1af19-b0a6-4340-b8df-3fe3ed581a3f",
   "metadata": {},
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ce382b-d4fb-49db-8f76-a21121716d93",
   "metadata": {},
   "source": [
    "### Creating a directory to store ReLU layer's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e300f32-db57-44de-a0c8-f4a1a8e9fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_path = create_if_not_exists(path_where_all_parameters_be_stored, \"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87ce11b0-f193-4460-af29-019a58287200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./relu/'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e8ce4-dc8a-4743-b365-6cb9943ec277",
   "metadata": {},
   "source": [
    "### Saving ReLU layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "362d3e88-443a-4572-9bde-f7b32a68e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "for i in range(0,len(relu)):\n",
    "    if type(relu[i]) != str:\n",
    "        relu_tensor = relu[i]\n",
    "        write_tensor_to_file(relu_tensor, relu_path, \"relu_layer_{}.txt\".format(layer))\n",
    "        layer += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e2353-d40f-4eb6-9f04-ddaa8d7cc797",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc7dc3-802d-4934-a85f-6a8a91340d54",
   "metadata": {},
   "source": [
    "### Creating a directory to store linear layer's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2981bd1f-bf47-4f68-8d28-80909bd3c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_path = create_if_not_exists(path_where_all_parameters_be_stored, \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7293b06-459f-4b56-880f-427d024ecde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./linear/'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fc2fd-3104-41e8-847a-dab41a12b450",
   "metadata": {},
   "source": [
    "### Saving linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bedbb8f-a6b8-4900-a577-2c5337865335",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 1\n",
    "for i in range(0,len(linear)):\n",
    "    if type(linear[i]) != str:\n",
    "        linear_tensor = linear[i]\n",
    "        write_tensor_to_file(linear_tensor, linear_path, \"linear_layer_{}.txt\".format(layer))\n",
    "        layer += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
