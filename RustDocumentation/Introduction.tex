\mainsection{Introduction}

\subsection{Installation}
You {\bf may} need to be on the Rust nightly build and
you probably also need to add \verb|wasm| support by typing
\begin{verbatim}
    rustup target add wasm32-unknown-unknown
\end{verbatim}

\subsection{General Rust Programs}
Programs live in folders (just like in Mamba),
however the location of the Rust program folders is now
in
\begin{verbatim}
   RustPrograms/examples/<program name>/
\end{verbatim}
The main Rust program in this folder should be called
\verb|main.rs|. To compile the program in the above
folder you execute
\begin{verbatim}
   ./compile-rust.sh <program name>
\end{verbatim}
This will execute the compiler and place the associated \verb|.bc|
and \verb|.sch| files within the above folder.
To run the program you then have to execute
\begin{verbatim}
   ./Player.x 0 RustPrograms/examples/<program name>/
\end{verbatim}
There are various options you can pass to the compiler,
these include
\begin{itemize}
     \item  \verb|-A|. This places the associated Scale assembly
           files \verb|.asm| in the program folder. These are the
           assembly files {\em before} they have been passed through
           the \verb|scasm| optimization steps.
\end{itemize}
Any other options (like \verb|-O1, -O2, -O3|) get passed to scasm.

\vspace{3mm}

\noindent
Your Rust programs should start with the following preamble:
\begin{lstlisting}
    #![no_std]
    #![no_main]
    #![feature(const_evaluatable_checked)]

    #[scale::main(KAPPA = 40)]
    #[inline(always)]
    fn main() {
       // your code goes here
    }
\end{lstlisting}
The \verb|main!| part defines the \verb|KAPPA| parameter,
which is the global statistical security 
parameter which your program will use. Unlike in Mamba we define a
single such parameter which is used for all operations;
e.g. the \verb|SecretInteger| and \verb|SecretFixed| types
(and for the \verb|sfloat| when it ends up being defined).


\subsection{Testing}
The compiler can compile into two different targets,
the real SCALE target, which is done as above,
and a Test target, which is used to test the system.
In the test system the Rust program is simply run on a single
machine, and all secret operations are performed in the clear.
The other difference between the two modes is in the operation
of the \verb|test| operations which are given later.
In the SCALE target they create a write to memory, in the
Test target they read from the memory output by the SCALE
execution and then compare this value to the value which
is being tested.

\vspace{3mm}

\noindent
{\bf Note:} The test instructions need to occur on a well
defined, unique, line. Thus you cannot place a test function call
within a loop. All test operations should be executed within
the main function.
The line number needs to be less than 1000; if you execute
a test instruction on a line number greater than 1000 then
undefined behaviour can occur.

To compile and run the test target you invoke
\begin{verbatim}
   ./Scripts/test_wasm.sh <program name>
\end{verbatim}
which will take all \verb|*.rs| files in \verb|RustPrograms/examples/<program name>|,
convert them to \verb|wasm|, and then to scale assembly and then run
them in the SCALE test environment. After that it will run the
same programs in the clear and compare their approprate \verb|test| calls.

To compile and run all the test programs on the current configuration
defined by \verb|Setup.x| use
\begin{verbatim}
   ./Scripts/test_wasm.sh
\end{verbatim}
To compile and run all the test programs on all the test configurations you invoke
\begin{verbatim}
   ./run_tests.sh test_wasm
\end{verbatim}

\subsection{Things Working/Not Working}
The advantage of using the Rust over Mamba driving language is that we now
have a means to start defining more complex operations in a clearer manner.
One should think of Mamba not as a language, but as a high-level assembler.

\subsubsection{Not Working}
Currently you cannot access from Rust the following features of Scale
\begin{itemize}
     \item More than one online thread.
     \item Some native SCALE printing operations.
     \item \verb|sfloat|, \verb|cfloat|.
\end{itemize}
We are currently working on fixing the above.

The vectorized (i.e. SIMD) instructions in SCALE will not be
supported by the Rust pipeline. To access them the programmer
would need to use special constructs etc, which make using them
difficult. The gain is marginal, over program complexity, and we
can achieve the same effect by other changes in the runtime which
can apply to a wider class of programs.

\subsubsection{Working}
In comparison to Mamba the following work or are improvements
in our Rust compilation pipeline.
\begin{itemize}
     \item You cannot directly access comparison etc operations on 
	     \verb|ClearModp|/\verb|SecretModp| types, after all what
	      does comparison of two integers modulo $p$ mean mathematically?
	      Instead these operations are available via the
	      \verb|ClearInteger<K>|/\verb|SecretInteger<K>| types.
	      Thus you need to coerce your value into one of these
	      types first (which costs nothing), and then apply 
	      the desired operation. This avoids programmer errors,
	      as the programmer needs to know how big an integer is
	      before it can be compared to another.
     \item Recursive function calls.
     \item Automatic assignment of mutable local variables across
	     conditional basic blocks; avoiding the need to manually
	     work out memory allocations.
     \item No distinction between the old `python'-for loops (unrolled)
	     vs `Mamba'-for loops (rolled). The distinction is determined
	   by the compiler as an optimization.
     \item Conveniently allocating memory instead of having to keep 
	   track of it manually in the code.
     \item Dynamic memory allocation and deletion for arrays etc is done 
	     automatically.
     \item Full math library for the \verb|ClearIEEE| and \verb|SecretIEEE|
	     types (none of which are available in Mamba).
     \item In working through the code we found lots of assumptions which
	     Mamba makes which are not strictly true. For example when doing
	     integer comparison of objects modulo $p$ it (sometimes) assumes that the
	     underlying integer is less than 64-bits in size.
	     Whilst for a lot of code this might be perfectly correct, for 
	     some use cases it is not (for example fixed point arithmetic
	     of high precision for large numbers). Thus when making the libraries for
	     arithmetic we have assumed all possible use cases are possible.
	     Thus code may be less efficient than Mamba, but it will be hopefully
	     more correct.
\end{itemize}


\subsection{Under The Hood: How the magic works...}

\noindent
{\bf{Wasm}} is a stack based assembly language.
There are no registers. Instead, all instruction arguments are pushed and popped on a stack.
As an example, take $42 + 3$ in \verb|wasm|. First $42$ is pushed to the stack, then $3$ is pushed to the
stack and finally $add$ pops two values off the stack, adds them and pushes the result back onto the stack.

\begin{lstlisting}
   i32.const 42
   i32.const 3
   i32.add
\end{lstlisting}

~ \\

\noindent
{\bf{Scale}} is a register based assembly language.
While it does have a stack, meaning we could emulate \verb|wasm| 1:1 by generating

\begin{lstlisting}
    ldint r0 42
    pushint r0

    ldint r0 3
    pushint r0

    popint r1
    popint r2
    addint r3 r1 r2
    pushint r3
\end{lstlisting}
But that would be very inefficient.

~ \\

\noindent{\bf{Basic Transpilation}}
What we do instead is to essentially execute the \verb|wasm|, just like mamba did with its source. So when we see
\begin{lstlisting}
    i32.const 42
\end{lstlisting}
we push an \verb|Operand::Value(Const::Int(42))| to the wasca-stack.
The wasca-stack only exists during transpilation and is entirely unrelated to the \verb|push*| and \verb|pop*|
operations from scale.

When we see
\begin{lstlisting}
    i32.add
\end{lstlisting}
We pop two values off the wasca-stack. If the values are \verb|Operand::Value| and not
\verb|Operand::Register|, we begin by generating

\begin{lstlisting}
    ldint some_new_register popped_operand_value
\end{lstlisting}
This conversion is automatically done by the \verb|val_to_reg| function.
The $some_new_register$ is `allocated' by increasing a global counter in wasca.
This way we always get a new register and guarantee that all registers are used in a SSA manner.

Now that we have two \verb|Operand::Register| (either directly from popping or from the conversion)
we allocate a result register and generate the add instruction.
\begin{lstlisting}
    addint result_reg reg1 reg2
\end{lstlisting}
Finally, we push an \verb|Operand::Register| for the result register onto the wasca-stack.
The next operation can then pop the value off the stack in order to obtain its arguments.


\subsubsection{Local variables}

Sometimes a stack based approach makes certain code very complex or nearly impossible to write.
For this reason \verb|wasm| has function-local variables.
Every function declares at the start which local variables it has and of which type they are. Unfortunately \verb|wasm| only has
\verb|i32 i64 f32 f64 i128| available to us.
Technically there is also an externref meta-type that allows code to create
its own types, but LLVM (and thus Rust) does not support this yet.
This means that while we have 5 \verb|wasm| types that could map to the five SCALE types (where here we use their Rust names)
\verb|i64 SecretI64 ClearModp SecretModp SecretBit|.
The \verb|wasm| types have no relation to the types used from Rust, beyond that \verb|i64| in Rust is also
\verb|i64| in \verb|wasm|. Unfortunately \verb|u64| in Rust is also \verb|i64| in \verb|wasm|, and the only way
to notice this in \verb|wasm| is that there are some unsigned operations on \verb|i64|. We can ignore all this for most of the time.

The interesting part is that \verb|SecretModp|, \verb|SecretI64|, and \verb|ClearModp| are all encoded as
\verb|f64|, \verb|f32| and \verb|i128|, without ever using them as such.
The reason this works out at all is that we do not translate operations on these types to \verb|wasm| operations,
but instead translate them to extern function calls which we will lower to the appropriate instructions directly.
\verb|SecretBit| is encoded as \verb|SecretI64| by being converted to and from \verb|SecretI64| at all use sites.
This is not very efficient, but we will get efficiency back once LLVM and Rust permit us to declare externref types.

\subsubsection{Extern function calls}

Operations on anything but \verb|i64| as well as any SCALE instructions that just does not have an equivalent in \verb|wasm|
are represented as extern function calls. As an example, take the adds instruction. Its arguments as per the documentation are
\verb|(dest: sw, left: s, right: s).|
From this, the transpiler automatically figures out that there is one return (output) value and two arguments.
In Rust, this generates a
\begin{lstlisting}
    extern "C" {
        fn __adds(left: Secret, right: Secret) -> Secret;
    }
\end{lstlisting}
Any call to \verb|__adds| will cause the \verb|wasm| code to leave two values on the \verb|wasm| stack and expect that after
the call the return value will be on the \verb|wasm| stack. So, similarly to the builtin addition for \verb|i64|,
we will pop two values off the stack, make sure they are registers by optionally generating
\verb|lds| instructions and then push the return register onto the stack.

Some SCALE instructions have multiple output/return values. Examples are the triple and square instructions.
Unfortunately Rust/LLVM does not really support this yet, so we had to work around it a bit.
For these functions we generate a \verb|push_multi_arg_triple| function which has no return values at all.
This function pushes values onto the transpiler stack, even though the \verb|wasm| stack would not contain any values.
     {\bf Remember:} The transpiler stack has nothing to do with the SCALE stack at all,
it is just equivalent to the \verb|wasm| stack most of the time, unless we do hacks as described in this section.
Now, after these values are on the stack, we use transpiler stack manipulation functions (extern functions by themselves)
to get the values back. In essence, the \verb|__triple| `extern' function is thus not an extern function but looks like
\begin{lstlisting}
    #[inline(always)]
    pub fn __triple() -> (Secret, Secret, Secret) {
        push_multi_arg_triple();
        let a = pop_multiarg();
        let b = pop_multiarg();
        let c = pop_multiarg();
        (a, b, c)
    }
\end{lstlisting}

~\\

\noindent
{\bf Function calls:}
Most function calls in Rust do not actually end up with a function call in
\verb|wasm|. This is because usually the optimizer inlines function calls aggressively.
In some cases we do want function calls instead of aggressive inlining.
In the future there will be a way to force the compiler to generate a function call at
specific sites.

\subsubsection{Memory Management}
Memory is allocated by use of the \verb|New| and \verb|Delete| operations in the
SCALE runtime.
This is mainly hidden from the user, and the user should probably not use these
(just as a C++ programmer should probably avoid \verb|new| and \verb|delete|
and stick to the STL).

For single value allocations, we have the \verb|scale_std::heap::Box| that works similarly to Array, but has no indices on its operations. We should analyze whether we need any other memory datastructures and how much users should be able to nest them (array of slices of boxes or similar).

Right now we use regular Rust globals for the memory allocator. This has the disadvantage of requiring memory itself (in the compiler-used memory region). This makes various operations very verbose (10-20 instructions for a single memor allcation invocation). If we add special functions that handle the memory allocations for us in wasca, we can optimize all this to just use a single register per memory bank.

